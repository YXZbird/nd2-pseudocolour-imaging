{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306d171c-d41f-446b-8092-cdeecdcb1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 ND2 file(s) in: C:\\Users\\yixiao Zhou\\Desktop\\bioimage\\input\n",
      "\n",
      "Processing: RMC1 L152WT MOC EEA CD63 H PH 60OIL 0000.032.nd2\n",
      "  Saved outputs for: RMC1 L152WT MOC EEA CD63 H PH 60OIL 0000.032\n",
      "\n",
      "Quantification summary saved: C:\\Users\\yixiao Zhou\\Desktop\\bioimage\\output\\quant_summary.csv\n",
      "Combined object table saved: C:\\Users\\yixiao Zhou\\Desktop\\bioimage\\output\\objects_488_all_files.csv\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ND2 -> preprocessing -> pseudocolour RGB export\n",
    "+ quantitative summary (per-file)\n",
    "+ object-level measurements (scikit-image regionprops_table; per-file CSV)\n",
    "\n",
    "Pipeline\n",
    "1) Read ND2 via ND2Reader and normalise to (C, Z, Y, X) (first timepoint if T exists)\n",
    "2) Z-project selected channels (max/mean)\n",
    "3) Per-channel preprocessing: background subtraction, normalisation, CLAHE, smoothing\n",
    "4) Pseudocolour mapping and export (TIFF + JPG)\n",
    "5) Quantification:\n",
    "   A) Per-file distribution stats (nonzero pixels)\n",
    "   B) Otsu-based signal masks: area fraction, mean signal\n",
    "   C) Inter-channel correlation within union of signal masks (proxy)\n",
    "   D) Object-level features from signal mask using scikit-image:\n",
    "      - label, area, mean intensity, eccentricity, solidity, centroid\n",
    "      Exported to CSV per file, and optionally concatenated to one CSV.\n",
    "\n",
    "Dependencies\n",
    "  pip install nd2reader numpy pandas scikit-image tifffile pillow matplotlib\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nd2reader import ND2Reader\n",
    "from skimage import exposure, filters, img_as_ubyte, morphology, measure\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0. Configuration\n",
    "# =========================\n",
    "INPUT_DIR = Path(r\"C:\\XXX\\input\")\n",
    "OUTPUT_DIR = Path(r\"C:\\XXX\\output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Channel indices (adjust if acquisition order differs)\n",
    "CH_DAPI = 0\n",
    "CH_488 = 1\n",
    "CH_568 = 2\n",
    "\n",
    "# Z projection method: \"max\" or \"mean\"\n",
    "PROJECTION = \"max\"\n",
    "\n",
    "# Preprocessing parameters\n",
    "BG_SIGMA = 50          # background blur sigma\n",
    "CLAHE_CLIP = 0.01      # CLAHE clip limit\n",
    "SMOOTH_SIGMA = 1       # post-CLAHE smoothing sigma\n",
    "\n",
    "# Export options\n",
    "SAVE_TIFF = True\n",
    "SAVE_JPG = True\n",
    "SAVE_QC_PNG = False             # raw projections + RGB preview\n",
    "SAVE_INTENSITY_HISTS = False    # per-file intensity histograms\n",
    "\n",
    "# Quantification options\n",
    "MIN_OBJECT_SIZE = 200\n",
    "USE_SIGNAL_MASK_FOR_STATS = True\n",
    "\n",
    "# Object-level quantification (scikit-image)\n",
    "EXPORT_OBJECT_TABLE_PER_FILE = True\n",
    "EXPORT_OBJECT_TABLE_COMBINED = True\n",
    "OBJECT_FEATURES = [\n",
    "    \"label\",\n",
    "    \"area\",\n",
    "    \"mean_intensity\",\n",
    "    \"eccentricity\",\n",
    "    \"solidity\",\n",
    "    \"centroid\",\n",
    "]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1. Core image functions\n",
    "# =========================\n",
    "def ensure_czyx(arr: np.ndarray) -> np.ndarray | None:\n",
    "    \"\"\"Normalise ND2 array to (C, Z, Y, X); if (T, C, Z, Y, X) take T=0.\"\"\"\n",
    "    if arr.ndim == 5:\n",
    "        return arr[0]\n",
    "    if arr.ndim == 4:\n",
    "        return arr\n",
    "    return None\n",
    "\n",
    "\n",
    "def project_z(stack_zyx: np.ndarray, method: str = \"max\") -> np.ndarray:\n",
    "    \"\"\"Project (Z, Y, X) -> (Y, X). If already 2D, return unchanged.\"\"\"\n",
    "    if stack_zyx.ndim == 2:\n",
    "        return stack_zyx\n",
    "    if stack_zyx.ndim != 3:\n",
    "        raise ValueError(f\"Expected 2D or 3D stack, got {stack_zyx.shape}\")\n",
    "    m = method.lower()\n",
    "    if m == \"max\":\n",
    "        return np.max(stack_zyx, axis=0)\n",
    "    if m == \"mean\":\n",
    "        return np.mean(stack_zyx, axis=0)\n",
    "    raise ValueError(f\"Unknown projection method: {method}\")\n",
    "\n",
    "\n",
    "def preprocess_channel(\n",
    "    ch2d: np.ndarray,\n",
    "    bg_sigma: float = 50,\n",
    "    clahe_clip: float = 0.01,\n",
    "    smooth_sigma: float = 1,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess a 2D fluorescence image for robust visualisation and simple quantification.\n",
    "    Returns float32 image in [0, 1].\n",
    "    \"\"\"\n",
    "    ch = ch2d.astype(np.float32)\n",
    "\n",
    "    # Background subtraction\n",
    "    bg = filters.gaussian(ch, sigma=bg_sigma)\n",
    "    ch = ch - bg\n",
    "    ch[ch < 0] = 0\n",
    "\n",
    "    # Normalise to [0, 1]\n",
    "    ch = (ch - ch.min()) / (np.ptp(ch) + 1e-8)\n",
    "\n",
    "    # CLAHE\n",
    "    ch = exposure.equalize_adapthist(ch, clip_limit=clahe_clip)\n",
    "\n",
    "    # Mild smoothing\n",
    "    ch = filters.gaussian(ch, sigma=smooth_sigma)\n",
    "\n",
    "    # Re-normalise\n",
    "    ch = (ch - ch.min()) / (np.ptp(ch) + 1e-8)\n",
    "    return ch.astype(np.float32)\n",
    "\n",
    "\n",
    "def make_signal_mask(ch_norm: np.ndarray, min_size: int = 200) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Conservative signal mask using Otsu thresholding on a [0,1] image.\n",
    "    Removes small objects for stability.\n",
    "    \"\"\"\n",
    "    th = filters.threshold_otsu(ch_norm)\n",
    "    mask = ch_norm > th\n",
    "    mask = morphology.remove_small_objects(mask, min_size=min_size)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. Quantification helpers\n",
    "# =========================\n",
    "def safe_stats(x: np.ndarray) -> dict:\n",
    "    \"\"\"Compute robust summary stats for a 1D array.\"\"\"\n",
    "    if x.size == 0:\n",
    "        return {\"n\": 0, \"mean\": np.nan, \"median\": np.nan, \"p10\": np.nan, \"p90\": np.nan, \"std\": np.nan}\n",
    "    return {\n",
    "        \"n\": int(x.size),\n",
    "        \"mean\": float(np.mean(x)),\n",
    "        \"median\": float(np.median(x)),\n",
    "        \"p10\": float(np.percentile(x, 10)),\n",
    "        \"p90\": float(np.percentile(x, 90)),\n",
    "        \"std\": float(np.std(x, ddof=1)) if x.size > 1 else 0.0,\n",
    "    }\n",
    "\n",
    "\n",
    "def corr_in_mask(a: np.ndarray, b: np.ndarray, mask: np.ndarray) -> float:\n",
    "    \"\"\"Pearson correlation in a masked region (NaN if insufficient).\"\"\"\n",
    "    aa = a[mask].ravel()\n",
    "    bb = b[mask].ravel()\n",
    "    if aa.size < 10:\n",
    "        return float(\"nan\")\n",
    "    aa = aa - aa.mean()\n",
    "    bb = bb - bb.mean()\n",
    "    denom = (np.sqrt((aa**2).sum()) * np.sqrt((bb**2).sum())) + 1e-12\n",
    "    return float((aa * bb).sum() / denom)\n",
    "\n",
    "\n",
    "def save_qc_png(out_path: Path, dapi_raw: np.ndarray, g488_raw: np.ndarray, r568_raw: np.ndarray, rgb_8bit: np.ndarray) -> None:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 4, 1); plt.imshow(dapi_raw, cmap=\"gray\"); plt.title(\"Raw DAPI (proj)\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 2); plt.imshow(g488_raw, cmap=\"gray\"); plt.title(\"Raw 488 (proj)\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 3); plt.imshow(r568_raw, cmap=\"gray\"); plt.title(\"Raw 568 (proj)\"); plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 4); plt.imshow(rgb_8bit); plt.title(\"Pseudo-colour RGB\"); plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_intensity_hist(out_path: Path, g488: np.ndarray, r568: np.ndarray, dapi: np.ndarray) -> None:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def vals(x):\n",
    "        v = x[x > 0].ravel()\n",
    "        return v if v.size else np.array([0.0], dtype=np.float32)\n",
    "\n",
    "    v488 = vals(g488)\n",
    "    v568 = vals(r568)\n",
    "    vdapi = vals(dapi)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(v488, bins=60, alpha=0.6, label=\"488\", density=True)\n",
    "    plt.hist(v568, bins=60, alpha=0.6, label=\"568\", density=True)\n",
    "    plt.hist(vdapi, bins=60, alpha=0.6, label=\"DAPI\", density=True)\n",
    "    plt.xlabel(\"Normalised intensity\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Intensity distributions (post-preprocessing)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. Main batch processing\n",
    "# =========================\n",
    "def main() -> None:\n",
    "    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(\".nd2\")]\n",
    "    print(f\"Found {len(files)} ND2 file(s) in: {INPUT_DIR}\")\n",
    "\n",
    "    if not files:\n",
    "        print(\"No ND2 files found. Check INPUT_DIR.\")\n",
    "        return\n",
    "\n",
    "    summary_rows: list[dict] = []\n",
    "    all_object_tables: list[pd.DataFrame] = []\n",
    "\n",
    "    for fname in files:\n",
    "        fpath = INPUT_DIR / fname\n",
    "        print(f\"\\nProcessing: {fpath.name}\")\n",
    "\n",
    "        # ---- Read ND2 ----\n",
    "        nd2 = ND2Reader(str(fpath))\n",
    "        nd2.bundle_axes = (\"c\", \"z\", \"y\", \"x\")\n",
    "        nd2.iter_axes = \"t\" if \"t\" in nd2.axes else \"\"\n",
    "\n",
    "        data = np.array(nd2)\n",
    "        data_czyx = ensure_czyx(data)\n",
    "\n",
    "        if data_czyx is None:\n",
    "            print(\"  Skip: unexpected ND2 dimensions:\", data.shape)\n",
    "            continue\n",
    "\n",
    "        C, Z, Y, X = data_czyx.shape\n",
    "        required = max(CH_DAPI, CH_488, CH_568) + 1\n",
    "        if C < required:\n",
    "            print(f\"  Skip: insufficient channels (C={C}, need >= {required})\")\n",
    "            continue\n",
    "\n",
    "        # ---- Z projection ----\n",
    "        dapi_raw = project_z(data_czyx[CH_DAPI], method=PROJECTION)\n",
    "        g488_raw = project_z(data_czyx[CH_488], method=PROJECTION)\n",
    "        r568_raw = project_z(data_czyx[CH_568], method=PROJECTION)\n",
    "\n",
    "        # ---- Preprocessing ----\n",
    "        dapi = preprocess_channel(dapi_raw, BG_SIGMA, CLAHE_CLIP, SMOOTH_SIGMA)\n",
    "        g488 = preprocess_channel(g488_raw, BG_SIGMA, CLAHE_CLIP, SMOOTH_SIGMA)\n",
    "        r568 = preprocess_channel(r568_raw, BG_SIGMA, CLAHE_CLIP, SMOOTH_SIGMA)\n",
    "\n",
    "        # ---- Pseudocolour mapping (R<-488, G<-568, B<-DAPI) ----\n",
    "        rgb = np.dstack([g488, r568, dapi]).astype(np.float32)\n",
    "        rgb_8bit = img_as_ubyte(np.clip(rgb, 0, 1))\n",
    "\n",
    "        base = Path(fname).stem\n",
    "        tif_path = OUTPUT_DIR / f\"{base}_rgb.tif\"\n",
    "        jpg_path = OUTPUT_DIR / f\"{base}_rgb.jpg\"\n",
    "        qc_path = OUTPUT_DIR / f\"{base}_qc.png\"\n",
    "        hist_path = OUTPUT_DIR / f\"{base}_intensity_hist.png\"\n",
    "\n",
    "        # ---- Save images ----\n",
    "        if SAVE_TIFF:\n",
    "            tiff.imwrite(str(tif_path), rgb_8bit)\n",
    "        if SAVE_JPG:\n",
    "            Image.fromarray(rgb_8bit).save(str(jpg_path), format=\"JPEG\", quality=95, subsampling=0)\n",
    "        if SAVE_QC_PNG:\n",
    "            save_qc_png(qc_path, dapi_raw, g488_raw, r568_raw, rgb_8bit)\n",
    "        if SAVE_INTENSITY_HISTS:\n",
    "            save_intensity_hist(hist_path, g488, r568, dapi)\n",
    "\n",
    "        # =========================\n",
    "        # 4. Quantification (per-file)\n",
    "        # =========================\n",
    "        row = {\n",
    "            \"file\": fname,\n",
    "            \"shape_CZYX\": f\"{C}x{Z}x{Y}x{X}\",\n",
    "            \"projection\": PROJECTION,\n",
    "            \"bg_sigma\": BG_SIGMA,\n",
    "            \"clahe_clip\": CLAHE_CLIP,\n",
    "            \"smooth_sigma\": SMOOTH_SIGMA,\n",
    "        }\n",
    "\n",
    "        # Global (nonzero) intensity distributions\n",
    "        v488 = g488[g488 > 0].ravel()\n",
    "        v568 = r568[r568 > 0].ravel()\n",
    "        vdapi = dapi[dapi > 0].ravel()\n",
    "\n",
    "        for k, v in safe_stats(v488).items():\n",
    "            row[f\"g488_{k}\"] = v\n",
    "        for k, v in safe_stats(v568).items():\n",
    "            row[f\"r568_{k}\"] = v\n",
    "        for k, v in safe_stats(vdapi).items():\n",
    "            row[f\"dapi_{k}\"] = v\n",
    "\n",
    "        # Signal-region metrics (Otsu masks)\n",
    "        if USE_SIGNAL_MASK_FOR_STATS:\n",
    "            mask_488 = make_signal_mask(g488, min_size=MIN_OBJECT_SIZE)\n",
    "            mask_568 = make_signal_mask(r568, min_size=MIN_OBJECT_SIZE)\n",
    "\n",
    "            row[\"mask488_area_fraction\"] = float(mask_488.mean())\n",
    "            row[\"mask568_area_fraction\"] = float(mask_568.mean())\n",
    "\n",
    "            row[\"g488_mean_in_mask488\"] = float(g488[mask_488].mean()) if mask_488.any() else float(\"nan\")\n",
    "            row[\"r568_mean_in_mask568\"] = float(r568[mask_568].mean()) if mask_568.any() else float(\"nan\")\n",
    "\n",
    "            # Correlation in union mask (proxy; not a colocalisation metric)\n",
    "            union = mask_488 | mask_568\n",
    "            row[\"corr_488_568_in_union_mask\"] = corr_in_mask(g488, r568, union)\n",
    "        else:\n",
    "            mask_488 = None\n",
    "            mask_568 = None\n",
    "            row[\"mask488_area_fraction\"] = float(\"nan\")\n",
    "            row[\"mask568_area_fraction\"] = float(\"nan\")\n",
    "            row[\"g488_mean_in_mask488\"] = float(\"nan\")\n",
    "            row[\"r568_mean_in_mask568\"] = float(\"nan\")\n",
    "            row[\"corr_488_568_in_union_mask\"] = float(\"nan\")\n",
    "\n",
    "        summary_rows.append(row)\n",
    "\n",
    "        # =========================\n",
    "        # 5. Object-level quantification (scikit-image)\n",
    "        # =========================\n",
    "        if EXPORT_OBJECT_TABLE_PER_FILE and (mask_488 is not None) and mask_488.any():\n",
    "            labels_488 = measure.label(mask_488)\n",
    "\n",
    "            props = measure.regionprops_table(\n",
    "                labels_488,\n",
    "                intensity_image=g488,\n",
    "                properties=OBJECT_FEATURES,\n",
    "            )\n",
    "            df_obj = pd.DataFrame(props)\n",
    "            df_obj.insert(0, \"file\", fname)\n",
    "            df_obj.insert(1, \"base\", base)\n",
    "            df_obj.insert(2, \"channel\", \"488\")\n",
    "            df_obj.insert(3, \"projection\", PROJECTION)\n",
    "\n",
    "            # Save per-file object table\n",
    "            obj_csv = OUTPUT_DIR / f\"{base}_objects_488.csv\"\n",
    "            df_obj.to_csv(obj_csv, index=False)\n",
    "\n",
    "            # Keep for combined export\n",
    "            all_object_tables.append(df_obj)\n",
    "\n",
    "        print(f\"  Saved outputs for: {base}\")\n",
    "\n",
    "    # ---- Save per-file summary table ----\n",
    "    if summary_rows:\n",
    "        df_sum = pd.DataFrame(summary_rows)\n",
    "        out_csv = OUTPUT_DIR / \"quant_summary.csv\"\n",
    "        df_sum.to_csv(out_csv, index=False)\n",
    "        print(f\"\\nQuantification summary saved: {out_csv}\")\n",
    "\n",
    "    # ---- Save combined object table ----\n",
    "    if EXPORT_OBJECT_TABLE_COMBINED and all_object_tables:\n",
    "        df_all = pd.concat(all_object_tables, ignore_index=True)\n",
    "        out_obj = OUTPUT_DIR / \"objects_488_all_files.csv\"\n",
    "        df_all.to_csv(out_obj, index=False)\n",
    "        print(f\"Combined object table saved: {out_obj}\")\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52530d9-bd14-45c3-94e8-b226fa582338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bioimage)",
   "language": "python",
   "name": "bioimage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
